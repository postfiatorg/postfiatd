name: Halo2 Devnet Deploy Nodes

on:
  workflow_dispatch:
    inputs:
      node_type:
        description: 'Node type to deploy'
        required: true
        type: choice
        options:
          - validators
          - rpc
          - archive
          - all
      image_tag_suffix:
        description: 'Image tag suffix after devnet-halo2-{size}- (latest or short SHA)'
        required: false
        default: latest
        type: string
      reset_vhs:
        description: 'Reset Halo2 VHS after validator deployment'
        required: false
        type: boolean
        default: false
      rpc_domain:
        description: 'Optional RPC domain override'
        required: false
        type: string
      ws_domain:
        description: 'Optional WebSocket domain override'
        required: false
        type: string
      archive_domain:
        description: 'Optional archive RPC domain override'
        required: false
        type: string
      ws_archive_domain:
        description: 'Optional archive WebSocket domain override'
        required: false
        type: string
      loki_url:
        description: 'Optional Loki push URL override'
        required: false
        type: string
      confirm_scope:
        description: 'Type HALO2_DEVNET_ONLY to confirm isolation from devnet/testnet'
        required: true
        default: HALO2_DEVNET_ONLY
        type: string

concurrency:
  group: halo2-devnet-lifecycle
  cancel-in-progress: false

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      validator_hosts: ${{ steps.prepare.outputs.validator_hosts }}
      rpc_hosts: ${{ steps.prepare.outputs.rpc_hosts }}
      archive_hosts: ${{ steps.prepare.outputs.archive_hosts }}
      has_archive_hosts: ${{ steps.prepare.outputs.has_archive_hosts }}
      vhs_host: ${{ steps.prepare.outputs.vhs_host }}
      loki_url: ${{ steps.prepare.outputs.loki_url }}
      rpc_domain: ${{ steps.prepare.outputs.rpc_domain }}
      ws_domain: ${{ steps.prepare.outputs.ws_domain }}
      archive_domain: ${{ steps.prepare.outputs.archive_domain }}
      ws_archive_domain: ${{ steps.prepare.outputs.ws_archive_domain }}
    steps:
      - name: Validate scope and resolve Halo2 config
        id: prepare
        env:
          INPUT_NODE_TYPE: ${{ inputs.node_type }}
          INPUT_CONFIRM_SCOPE: ${{ inputs.confirm_scope }}
          INPUT_RPC_DOMAIN: ${{ inputs.rpc_domain }}
          INPUT_WS_DOMAIN: ${{ inputs.ws_domain }}
          INPUT_ARCHIVE_DOMAIN: ${{ inputs.archive_domain }}
          INPUT_WS_ARCHIVE_DOMAIN: ${{ inputs.ws_archive_domain }}
          INPUT_LOKI_URL: ${{ inputs.loki_url }}
          HALO2_VALIDATORS: ${{ vars.DEVNET_HALO2_VALIDATOR_HOSTS }}
          HALO2_RPC: ${{ vars.DEVNET_HALO2_RPC_HOSTS }}
          HALO2_ARCHIVE: ${{ vars.DEVNET_HALO2_ARCHIVE_HOSTS }}
          HALO2_VHS: ${{ vars.DEVNET_HALO2_VHS_HOST }}
          HALO2_LOKI: ${{ vars.DEVNET_HALO2_LOKI_URL }}
          HALO2_RPC_DOMAIN: ${{ vars.DEVNET_HALO2_RPC_DOMAIN }}
          HALO2_WS_DOMAIN: ${{ vars.DEVNET_HALO2_WS_DOMAIN }}
          HALO2_ARCHIVE_DOMAIN: ${{ vars.DEVNET_HALO2_ARCHIVE_DOMAIN }}
          HALO2_WS_ARCHIVE_DOMAIN: ${{ vars.DEVNET_HALO2_WS_ARCHIVE_DOMAIN }}
          DEVNET_VALIDATORS: ${{ vars.DEVNET_VALIDATOR_HOSTS }}
          DEVNET_RPC: ${{ vars.DEVNET_RPC_HOSTS }}
          DEVNET_ARCHIVE: ${{ vars.DEVNET_ARCHIVE_HOSTS }}
          TESTNET_VALIDATORS: ${{ vars.TESTNET_VALIDATOR_HOSTS }}
          TESTNET_RPC: ${{ vars.TESTNET_RPC_HOSTS }}
          TESTNET_ARCHIVE: ${{ vars.TESTNET_ARCHIVE_HOSTS }}
        run: |
          set -euo pipefail

          if [ "${INPUT_CONFIRM_SCOPE}" != "HALO2_DEVNET_ONLY" ]; then
            echo "confirm_scope must be HALO2_DEVNET_ONLY"
            exit 1
          fi

          python3 - <<'PY'
          import json
          import os
          import sys

          out_file = os.environ["GITHUB_OUTPUT"]

          def fail(msg: str) -> None:
            print(msg)
            sys.exit(1)

          def parse_hosts(name: str, required: bool = False):
            raw = (os.environ.get(name, "") or "").strip()
            if not raw:
              if required:
                fail(f"Missing required variable: {name}")
              return []
            try:
              parsed = json.loads(raw)
            except Exception as exc:
              fail(f"Invalid JSON in {name}: {exc}")
            if not isinstance(parsed, list) or any(not isinstance(i, str) or not i.strip() for i in parsed):
              fail(f"{name} must be a JSON array of non-empty strings")
            return [i.strip() for i in parsed]

          def choose(input_key: str, var_key: str, default: str) -> str:
            input_val = (os.environ.get(input_key, "") or "").strip()
            if input_val:
              return input_val
            var_val = (os.environ.get(var_key, "") or "").strip()
            return var_val or default

          node_type = (os.environ.get("INPUT_NODE_TYPE", "") or "").strip()
          if node_type not in {"validators", "rpc", "archive", "all"}:
            fail(f"Unsupported node_type: {node_type}")

          halo2_validators = parse_hosts("HALO2_VALIDATORS", required=False)
          halo2_rpc = parse_hosts("HALO2_RPC", required=False)
          halo2_archive = parse_hosts("HALO2_ARCHIVE", required=False)

          validator_set = set(halo2_validators)
          rpc_set = set(halo2_rpc)
          archive_set = set(halo2_archive)
          role_overlap = sorted(
              (validator_set & rpc_set)
              | (validator_set & archive_set)
              | (rpc_set & archive_set)
          )
          if role_overlap:
            fail(
              "Halo2 host overlap detected across validator/rpc/archive roles: "
              + ", ".join(role_overlap)
            )

          devnet_validators = parse_hosts("DEVNET_VALIDATORS", required=False)
          devnet_rpc = parse_hosts("DEVNET_RPC", required=False)
          devnet_archive = parse_hosts("DEVNET_ARCHIVE", required=False)
          testnet_validators = parse_hosts("TESTNET_VALIDATORS", required=False)
          testnet_rpc = parse_hosts("TESTNET_RPC", required=False)
          testnet_archive = parse_hosts("TESTNET_ARCHIVE", required=False)

          halo2_hosts = set(halo2_validators + halo2_rpc + halo2_archive)
          legacy_hosts = set(
              devnet_validators
              + devnet_rpc
              + devnet_archive
              + testnet_validators
              + testnet_rpc
              + testnet_archive
          )

          overlap = sorted(halo2_hosts.intersection(legacy_hosts))
          if overlap:
            fail(
              "Halo2 host overlap detected with live devnet/testnet inventory: "
              + ", ".join(overlap)
            )

          if node_type in {"validators", "all"} and not halo2_validators:
            fail("No Halo2 validator hosts configured")
          if node_type in {"rpc", "all"} and not halo2_rpc:
            fail("No Halo2 RPC hosts configured")
          if node_type == "archive" and not halo2_archive:
            fail("No Halo2 archive hosts configured")

          has_archive_hosts = bool(halo2_archive)

          values = {
            "validator_hosts": json.dumps(halo2_validators),
            "rpc_hosts": json.dumps(halo2_rpc),
            "archive_hosts": json.dumps(halo2_archive),
            "has_archive_hosts": "true" if has_archive_hosts else "false",
            "vhs_host": (os.environ.get("HALO2_VHS", "") or "").strip(),
            "loki_url": choose(
              "INPUT_LOKI_URL",
              "HALO2_LOKI",
              "http://infra-monitoring.devnet.postfiat.org:3100/loki/api/v1/push",
            ),
            "rpc_domain": choose(
              "INPUT_RPC_DOMAIN", "HALO2_RPC_DOMAIN", "rpc.halo2.devnet.postfiat.org"
            ),
            "ws_domain": choose(
              "INPUT_WS_DOMAIN", "HALO2_WS_DOMAIN", "ws.halo2.devnet.postfiat.org"
            ),
            "archive_domain": choose(
              "INPUT_ARCHIVE_DOMAIN",
              "HALO2_ARCHIVE_DOMAIN",
              "archive.halo2.devnet.postfiat.org",
            ),
            "ws_archive_domain": choose(
              "INPUT_WS_ARCHIVE_DOMAIN",
              "HALO2_WS_ARCHIVE_DOMAIN",
              "ws-archive.halo2.devnet.postfiat.org",
            ),
          }

          with open(out_file, "a", encoding="utf-8") as fh:
            for key, value in values.items():
              fh.write(f"{key}={value}\n")
          PY

  deploy-validator:
    if: ${{ inputs.node_type == 'validators' || inputs.node_type == 'all' }}
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        host: ${{ fromJson(needs.prepare.outputs.validator_hosts) }}
    steps:
      - name: Deploy Halo2 validator ${{ matrix.host }}
        uses: appleboy/ssh-action@v1.2.0
        env:
          IMAGE_TAG_SUFFIX: ${{ inputs.image_tag_suffix }}
          LOKI_URL: ${{ needs.prepare.outputs.loki_url }}
          DEPLOY_HOST: ${{ matrix.host }}
          VALIDATOR_TOKEN_MAP: ${{ secrets.DEVNET_HALO2_VALIDATOR_TOKEN_MAP }}
        with:
          host: ${{ matrix.host }}
          username: root
          key: ${{ secrets.VULTR_SSH_KEY }}
          envs: IMAGE_TAG_SUFFIX,LOKI_URL,DEPLOY_HOST,VALIDATOR_TOKEN_MAP
          script: |
            set -euo pipefail

            BASE_DIR=/opt/postfiatd-halo2
            PROJECT_NAME=postfiatd-halo2
            CONTAINER_NAME=postfiatd-halo2
            PROMTAIL_NAME=promtail-halo2
            IMAGE="agtipft/postfiatd:devnet-halo2-light-${IMAGE_TAG_SUFFIX}"

            echo "Configuring UFW firewall for Halo2 validator..."
            ufw --force reset
            ufw default deny incoming
            ufw default allow outgoing
            ufw allow 22/tcp comment 'SSH'
            ufw allow 2559/tcp comment 'Peer protocol'
            ufw --force enable

            mkdir -p "${BASE_DIR}/logs"
            cd "${BASE_DIR}"

            docker compose --project-name "${PROJECT_NAME}" down --remove-orphans 2>/dev/null || true
            docker rm -f "${CONTAINER_NAME}" "${PROMTAIL_NAME}" 2>/dev/null || true
            docker volume ls -q --filter "name=${PROJECT_NAME}" | xargs -r docker volume rm 2>/dev/null || true

            cat > docker-compose.yml << COMPOSE_EOF
            version: '3.8'
            services:
              postfiatd:
                image: ${IMAGE}
                container_name: ${CONTAINER_NAME}
                ports:
                  - "5005:5005"
                  - "2559:2559"
                  - "6005:6005"
                  - "6006:6006"
                  - "50051:50051"
                volumes:
                  - postfiatd-config:/etc/postfiatd
                  - postfiatd-data:/var/lib/postfiatd/db
                  - ./logs:/var/log/postfiatd
                user: "0:0"
                restart: unless-stopped
                logging:
                  driver: json-file
                  options:
                    max-size: "100m"
                    max-file: "10"

              promtail:
                image: grafana/promtail:3.0.0
                container_name: ${PROMTAIL_NAME}
                hostname: \${HOSTNAME}
                volumes:
                  - ./promtail-config.yml:/etc/promtail/config.yml:ro
                  - ./logs:/var/log/postfiatd:ro
                  - promtail-positions:/tmp
                command: >
                  -config.file=/etc/promtail/config.yml
                restart: unless-stopped
                depends_on:
                  - postfiatd

            volumes:
              postfiatd-config:
              postfiatd-data:
              promtail-positions:
            COMPOSE_EOF

            cat > promtail-config.yml << PROMTAIL_EOF
            server:
              http_listen_port: 9080
              grpc_listen_port: 0

            positions:
              filename: /tmp/positions.yaml

            clients:
              - url: ${LOKI_URL}
                external_labels:
                  hostname: $(hostname)

            scrape_configs:
              - job_name: postfiatd
                static_configs:
                  - targets:
                      - localhost
                    labels:
                      service_type: halo2-validator
                      network: devnet_halo2
                      __path__: /var/log/postfiatd/*.log
            PROMTAIL_EOF

            cat > .env << ENV_EOF
            HOSTNAME=$(hostname)
            ENV_EOF

            docker compose --project-name "${PROJECT_NAME}" pull
            docker compose --project-name "${PROJECT_NAME}" up -d

            VALIDATOR_TOKEN="$(python3 - <<'PY'
            import json
            import os

            token_map = (os.environ.get("VALIDATOR_TOKEN_MAP", "") or "").strip()
            deploy_host = (os.environ.get("DEPLOY_HOST", "") or "").strip()
            if not token_map or not deploy_host:
              print("")
            else:
              try:
                parsed = json.loads(token_map)
                if isinstance(parsed, dict):
                  token = parsed.get(deploy_host, "")
                  print(token if isinstance(token, str) else "")
                else:
                  print("")
              except Exception:
                print("")
            PY
            )"

            if [ -z "${VALIDATOR_TOKEN}" ]; then
              echo "ERROR: No validator token for ${DEPLOY_HOST}. Populate DEVNET_HALO2_VALIDATOR_TOKEN_MAP secret (JSON host->token)."
              exit 1
            fi

            docker exec "${CONTAINER_NAME}" bash -c "printf '\n[validator_token]\n%s\n' '${VALIDATOR_TOKEN}' >> /etc/postfiatd/postfiatd.cfg"
            docker compose --project-name "${PROJECT_NAME}" restart postfiatd

            echo "Waiting for Halo2 validator to start..."
            sleep 30

            if docker exec "${CONTAINER_NAME}" postfiatd server_info 2>/dev/null | grep -q "server_state"; then
              echo "Halo2 validator is healthy"
            else
              echo "Warning: Halo2 validator health check inconclusive"
            fi

  deploy-rpc:
    if: ${{ always() && (inputs.node_type == 'rpc' || inputs.node_type == 'all') && !cancelled() }}
    needs: [prepare, deploy-validator]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        host: ${{ fromJson(needs.prepare.outputs.rpc_hosts) }}
    steps:
      - name: Deploy Halo2 RPC ${{ matrix.host }}
        uses: appleboy/ssh-action@v1.2.0
        env:
          IMAGE_TAG_SUFFIX: ${{ inputs.image_tag_suffix }}
          LOKI_URL: ${{ needs.prepare.outputs.loki_url }}
          VHS_HOST: ${{ needs.prepare.outputs.vhs_host }}
          RPC_DOMAIN: ${{ needs.prepare.outputs.rpc_domain }}
          WS_DOMAIN: ${{ needs.prepare.outputs.ws_domain }}
        with:
          host: ${{ matrix.host }}
          username: root
          key: ${{ secrets.VULTR_SSH_KEY }}
          envs: IMAGE_TAG_SUFFIX,LOKI_URL,VHS_HOST,RPC_DOMAIN,WS_DOMAIN
          script: |
            set -euo pipefail

            BASE_DIR=/opt/postfiatd-halo2
            PROJECT_NAME=postfiatd-halo2
            CONTAINER_NAME=postfiatd-halo2
            PROMTAIL_NAME=promtail-halo2
            IMAGE="agtipft/postfiatd:devnet-halo2-medium-${IMAGE_TAG_SUFFIX}"

            echo "Configuring UFW firewall for Halo2 RPC..."
            ufw --force reset
            ufw default deny incoming
            ufw default allow outgoing
            ufw allow 22/tcp comment 'SSH'
            ufw allow 80/tcp comment 'HTTP (Caddy)'
            ufw allow 443/tcp comment 'HTTPS (RPC API)'
            ufw allow 2559/tcp comment 'Peer protocol'
            if [ -n "${VHS_HOST}" ]; then
              ufw allow from "${VHS_HOST}" to any port 5005 proto tcp comment 'Halo2 VHS Admin RPC'
            fi
            ufw --force enable

            echo "Configuring iptables rate limiting..."
            iptables -D INPUT -p tcp --dport 443 -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m connlimit --connlimit-above 50 -j DROP 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m state --state NEW -m limit --limit 100/second --limit-burst 50 -j ACCEPT 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m state --state NEW -j DROP 2>/dev/null || true
            iptables -I INPUT -p tcp --dport 443 -m state --state NEW -j DROP
            iptables -I INPUT -p tcp --dport 443 -m state --state NEW -m limit --limit 100/second --limit-burst 50 -j ACCEPT
            iptables -I INPUT -p tcp --dport 443 -m connlimit --connlimit-above 50 -j DROP
            iptables -I INPUT -p tcp --dport 443 -m state --state ESTABLISHED,RELATED -j ACCEPT
            apt-get install -y iptables-persistent 2>/dev/null || true
            netfilter-persistent save 2>/dev/null || true

            if ! command -v caddy >/dev/null 2>&1; then
              echo "Installing Caddy..."
              apt-get update
              apt-get install -y debian-keyring debian-archive-keyring apt-transport-https curl
              curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
              curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | tee /etc/apt/sources.list.d/caddy-stable.list
              apt-get update
              apt-get install -y caddy
            fi

            cat > /etc/caddy/Caddyfile << CADDY_EOF
            # Halo2 Devnet RPC Node
            # Managed by halo2-devnet-deploy.yml

            ${RPC_DOMAIN} {
                reverse_proxy localhost:5005
            }

            ${WS_DOMAIN} {
                reverse_proxy localhost:6005
            }

            :80 {
                respond /health 200
            }
            CADDY_EOF

            systemctl enable caddy
            systemctl restart caddy

            mkdir -p "${BASE_DIR}/logs"
            cd "${BASE_DIR}"

            docker compose --project-name "${PROJECT_NAME}" down --remove-orphans 2>/dev/null || true
            docker rm -f "${CONTAINER_NAME}" "${PROMTAIL_NAME}" 2>/dev/null || true
            docker volume ls -q --filter "name=${PROJECT_NAME}" | xargs -r docker volume rm 2>/dev/null || true

            cat > docker-compose.yml << COMPOSE_EOF
            version: '3.8'
            services:
              postfiatd:
                image: ${IMAGE}
                container_name: ${CONTAINER_NAME}
                ports:
                  - "5005:5005"
                  - "2559:2559"
                  - "127.0.0.1:6005:6005"
                  - "6006:6006"
                  - "50051:50051"
                volumes:
                  - postfiatd-config:/etc/postfiatd
                  - postfiatd-data:/var/lib/postfiatd/db
                  - ./logs:/var/log/postfiatd
                user: "0:0"
                restart: unless-stopped
                logging:
                  driver: json-file
                  options:
                    max-size: "100m"
                    max-file: "10"

              promtail:
                image: grafana/promtail:3.0.0
                container_name: ${PROMTAIL_NAME}
                hostname: \${HOSTNAME}
                volumes:
                  - ./promtail-config.yml:/etc/promtail/config.yml:ro
                  - ./logs:/var/log/postfiatd:ro
                  - promtail-positions:/tmp
                command: >
                  -config.file=/etc/promtail/config.yml
                restart: unless-stopped
                depends_on:
                  - postfiatd

            volumes:
              postfiatd-config:
              postfiatd-data:
              promtail-positions:
            COMPOSE_EOF

            cat > promtail-config.yml << PROMTAIL_EOF
            server:
              http_listen_port: 9080
              grpc_listen_port: 0

            positions:
              filename: /tmp/positions.yaml

            clients:
              - url: ${LOKI_URL}
                external_labels:
                  hostname: $(hostname)

            scrape_configs:
              - job_name: postfiatd
                static_configs:
                  - targets:
                      - localhost
                    labels:
                      service_type: halo2-rpc
                      network: devnet_halo2
                      __path__: /var/log/postfiatd/*.log
            PROMTAIL_EOF

            cat > .env << ENV_EOF
            HOSTNAME=$(hostname)
            ENV_EOF

            docker compose --project-name "${PROJECT_NAME}" pull
            docker compose --project-name "${PROJECT_NAME}" up -d

            echo "Waiting for Halo2 RPC to start..."
            sleep 30

            if docker exec "${CONTAINER_NAME}" postfiatd server_info 2>/dev/null | grep -q "server_state"; then
              echo "Halo2 RPC is healthy"
            else
              echo "Warning: Halo2 RPC health check inconclusive"
            fi

            echo "Configuring WebSocket, rate limits, and admin access..."
            docker exec "${CONTAINER_NAME}" sed -i '/^\[port_ws_public\]/,/^\[/ s/^protocol = wss$/protocol = ws/' /etc/postfiatd/postfiatd.cfg
            docker exec "${CONTAINER_NAME}" sed -i '/^\[port_ws_public\]/,/^\[/ s/^limit = [0-9]*$/limit = 100/' /etc/postfiatd/postfiatd.cfg
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^limit = ' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_ws_public\]/a limit = 100' /etc/postfiatd/postfiatd.cfg"
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^ip_limit = ' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[overlay\]/a ip_limit = 5' /etc/postfiatd/postfiatd.cfg"

            if [ -n "${VHS_HOST}" ]; then
              docker exec "${CONTAINER_NAME}" sed -i "s/^admin = 127.0.0.1$/admin = 127.0.0.1, ${VHS_HOST}/" /etc/postfiatd/postfiatd.cfg
            fi

            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^secure_gateway = 172.18.0.1$' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_rpc_admin_local\]/a secure_gateway = 172.18.0.1' /etc/postfiatd/postfiatd.cfg"
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^secure_gateway = 172.18.0.1$' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_ws_public\]/a secure_gateway = 172.18.0.1' /etc/postfiatd/postfiatd.cfg"

            docker compose --project-name "${PROJECT_NAME}" restart postfiatd
            sleep 15

            if curl -fsS http://localhost/health >/dev/null 2>&1; then
              echo "Caddy health check passed"
            else
              echo "Warning: Caddy health check failed"
            fi

  deploy-archive:
    if: ${{ always() && (inputs.node_type == 'archive' || inputs.node_type == 'all') && needs.prepare.outputs.has_archive_hosts == 'true' && !cancelled() }}
    needs: [prepare, deploy-validator]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        host: ${{ fromJson(needs.prepare.outputs.archive_hosts) }}
    steps:
      - name: Deploy Halo2 archive ${{ matrix.host }}
        uses: appleboy/ssh-action@v1.2.0
        env:
          IMAGE_TAG_SUFFIX: ${{ inputs.image_tag_suffix }}
          LOKI_URL: ${{ needs.prepare.outputs.loki_url }}
          VHS_HOST: ${{ needs.prepare.outputs.vhs_host }}
          ARCHIVE_DOMAIN: ${{ needs.prepare.outputs.archive_domain }}
          WS_ARCHIVE_DOMAIN: ${{ needs.prepare.outputs.ws_archive_domain }}
        with:
          host: ${{ matrix.host }}
          username: root
          key: ${{ secrets.VULTR_SSH_KEY }}
          envs: IMAGE_TAG_SUFFIX,LOKI_URL,VHS_HOST,ARCHIVE_DOMAIN,WS_ARCHIVE_DOMAIN
          script: |
            set -euo pipefail

            BASE_DIR=/opt/postfiatd-halo2
            PROJECT_NAME=postfiatd-halo2
            CONTAINER_NAME=postfiatd-halo2
            PROMTAIL_NAME=promtail-halo2
            IMAGE="agtipft/postfiatd:devnet-halo2-full-${IMAGE_TAG_SUFFIX}"

            echo "Configuring UFW firewall for Halo2 archive..."
            ufw --force reset
            ufw default deny incoming
            ufw default allow outgoing
            ufw allow 22/tcp comment 'SSH'
            ufw allow 80/tcp comment 'HTTP (Caddy)'
            ufw allow 443/tcp comment 'HTTPS (Archive API)'
            ufw allow 2559/tcp comment 'Peer protocol'
            if [ -n "${VHS_HOST}" ]; then
              ufw allow from "${VHS_HOST}" to any port 5005 proto tcp comment 'Halo2 VHS Admin RPC'
            fi
            ufw --force enable

            echo "Configuring iptables rate limiting..."
            iptables -D INPUT -p tcp --dport 443 -m state --state ESTABLISHED,RELATED -j ACCEPT 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m connlimit --connlimit-above 50 -j DROP 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m state --state NEW -m limit --limit 100/second --limit-burst 50 -j ACCEPT 2>/dev/null || true
            iptables -D INPUT -p tcp --dport 443 -m state --state NEW -j DROP 2>/dev/null || true
            iptables -I INPUT -p tcp --dport 443 -m state --state NEW -j DROP
            iptables -I INPUT -p tcp --dport 443 -m state --state NEW -m limit --limit 100/second --limit-burst 50 -j ACCEPT
            iptables -I INPUT -p tcp --dport 443 -m connlimit --connlimit-above 50 -j DROP
            iptables -I INPUT -p tcp --dport 443 -m state --state ESTABLISHED,RELATED -j ACCEPT
            apt-get install -y iptables-persistent 2>/dev/null || true
            netfilter-persistent save 2>/dev/null || true

            if ! command -v caddy >/dev/null 2>&1; then
              echo "Installing Caddy..."
              apt-get update
              apt-get install -y debian-keyring debian-archive-keyring apt-transport-https curl
              curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
              curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | tee /etc/apt/sources.list.d/caddy-stable.list
              apt-get update
              apt-get install -y caddy
            fi

            cat > /etc/caddy/Caddyfile << CADDY_EOF
            # Halo2 Devnet Archive Node
            # Managed by halo2-devnet-deploy.yml

            ${ARCHIVE_DOMAIN} {
                reverse_proxy localhost:5005
            }

            ${WS_ARCHIVE_DOMAIN} {
                reverse_proxy localhost:6005
            }

            :80 {
                respond /health 200
            }
            CADDY_EOF

            systemctl enable caddy
            systemctl restart caddy

            mkdir -p "${BASE_DIR}/logs"
            cd "${BASE_DIR}"

            docker compose --project-name "${PROJECT_NAME}" down --remove-orphans 2>/dev/null || true
            docker rm -f "${CONTAINER_NAME}" "${PROMTAIL_NAME}" 2>/dev/null || true
            docker volume ls -q --filter "name=${PROJECT_NAME}" | xargs -r docker volume rm 2>/dev/null || true

            cat > docker-compose.yml << COMPOSE_EOF
            version: '3.8'
            services:
              postfiatd:
                image: ${IMAGE}
                container_name: ${CONTAINER_NAME}
                ports:
                  - "5005:5005"
                  - "2559:2559"
                  - "127.0.0.1:6005:6005"
                  - "6006:6006"
                  - "50051:50051"
                volumes:
                  - postfiatd-config:/etc/postfiatd
                  - postfiatd-data:/var/lib/postfiatd/db
                  - ./logs:/var/log/postfiatd
                user: "0:0"
                restart: unless-stopped
                logging:
                  driver: json-file
                  options:
                    max-size: "100m"
                    max-file: "10"

              promtail:
                image: grafana/promtail:3.0.0
                container_name: ${PROMTAIL_NAME}
                hostname: \${HOSTNAME}
                volumes:
                  - ./promtail-config.yml:/etc/promtail/config.yml:ro
                  - ./logs:/var/log/postfiatd:ro
                  - promtail-positions:/tmp
                command: >
                  -config.file=/etc/promtail/config.yml
                restart: unless-stopped
                depends_on:
                  - postfiatd

            volumes:
              postfiatd-config:
              postfiatd-data:
              promtail-positions:
            COMPOSE_EOF

            cat > promtail-config.yml << PROMTAIL_EOF
            server:
              http_listen_port: 9080
              grpc_listen_port: 0

            positions:
              filename: /tmp/positions.yaml

            clients:
              - url: ${LOKI_URL}
                external_labels:
                  hostname: $(hostname)

            scrape_configs:
              - job_name: postfiatd
                static_configs:
                  - targets:
                      - localhost
                    labels:
                      service_type: halo2-archive
                      network: devnet_halo2
                      __path__: /var/log/postfiatd/*.log
            PROMTAIL_EOF

            cat > .env << ENV_EOF
            HOSTNAME=$(hostname)
            ENV_EOF

            docker compose --project-name "${PROJECT_NAME}" pull
            docker compose --project-name "${PROJECT_NAME}" up -d

            echo "Waiting for Halo2 archive to start..."
            sleep 30

            if docker exec "${CONTAINER_NAME}" postfiatd server_info 2>/dev/null | grep -q "server_state"; then
              echo "Halo2 archive is healthy"
            else
              echo "Warning: Halo2 archive health check inconclusive"
            fi

            echo "Configuring WebSocket, rate limits, and admin access..."
            docker exec "${CONTAINER_NAME}" sed -i '/^\[port_ws_public\]/,/^\[/ s/^protocol = wss$/protocol = ws/' /etc/postfiatd/postfiatd.cfg
            docker exec "${CONTAINER_NAME}" sed -i '/^\[port_ws_public\]/,/^\[/ s/^limit = [0-9]*$/limit = 25/' /etc/postfiatd/postfiatd.cfg
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^limit = ' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_ws_public\]/a limit = 25' /etc/postfiatd/postfiatd.cfg"
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^ip_limit = ' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[overlay\]/a ip_limit = 5' /etc/postfiatd/postfiatd.cfg"

            if [ -n "${VHS_HOST}" ]; then
              docker exec "${CONTAINER_NAME}" sed -i "s/^admin = 127.0.0.1$/admin = 127.0.0.1, ${VHS_HOST}/" /etc/postfiatd/postfiatd.cfg
            fi

            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^secure_gateway = 172.18.0.1$' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_rpc_admin_local\]/a secure_gateway = 172.18.0.1' /etc/postfiatd/postfiatd.cfg"
            docker exec "${CONTAINER_NAME}" bash -c "grep -q '^secure_gateway = 172.18.0.1$' /etc/postfiatd/postfiatd.cfg || sed -i '/^\[port_ws_public\]/a secure_gateway = 172.18.0.1' /etc/postfiatd/postfiatd.cfg"

            docker compose --project-name "${PROJECT_NAME}" restart postfiatd
            sleep 15

            if curl -fsS http://localhost/health >/dev/null 2>&1; then
              echo "Caddy health check passed"
            else
              echo "Warning: Caddy health check failed"
            fi

  reset-vhs:
    if: ${{ always() && inputs.reset_vhs && (inputs.node_type == 'validators' || inputs.node_type == 'all') && !cancelled() }}
    needs: [prepare, deploy-validator, deploy-rpc, deploy-archive]
    runs-on: ubuntu-latest
    steps:
      - name: Validate VHS host
        run: |
          set -euo pipefail
          if [ -z "${{ needs.prepare.outputs.vhs_host }}" ]; then
            echo "reset_vhs=true requested, but DEVNET_HALO2_VHS_HOST is empty"
            exit 1
          fi
      - name: Reset Halo2 VHS
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: ${{ needs.prepare.outputs.vhs_host }}
          username: root
          key: ${{ secrets.VULTR_SSH_KEY }}
          script: |
            set -euo pipefail
            curl -fsSL https://raw.githubusercontent.com/postfiatorg/validator-history-service/main/scripts/reset-vhs.sh | bash
            echo "Halo2 VHS reset complete"
